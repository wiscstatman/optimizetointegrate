Associate editor's report

In this paper, the authors consider the sparse linear regression problem and study asymptotic properties of the weighted likelihood bootstrap for the lasso. Although the authors put a Bayesian emphasis in the paper including the title, to me, the results appear to be about exchangeable bootstrap for the lasso, at least in the way it is presented in its current form. Quite contrary to the title, the procedure has not been shown to approximate a posterior distribution in some well-defined setting. I don't find the discussion in Section 4.1 convincing. For a sparse prior, the posterior distribution is not approximated by a non-singular normal, but by a mixture of different dimensional normal (or under a stronger condition, by a single lower-dimensional normal); see Castillo, Schmidt-Hieber and van der Vaart (2015, Annals of Statistics, Vol 43, pp 1986-2018 --- this paper should be cited). The centering at the least square estimator is misfit too, as centering at the lasso estimator appears to be more appropriate in this context. The case of fixed p is not much interesting. This is not to say that the weighted bootstrap methodology is not useful for inference, but its connection with a conventional posterior distribution is questionable. The obtained results are thus about the bootstrap, and should be viewed in that way. There are some results on bootstrap for the lasso (some negative, some positive), and a thorough comparison with those results is essential.

I think to make the paper sensible, it should be presented as a bootstrap paper rather than a pseudo-Bayesian paper, and only concentrating on the results that are interesting in the modern context. The fixed p case is not much interesting and there is no need to separately state and prove this case (but may be absorbed inside a general statement and proof). Theorem 3.1 about a randomly weighted estimator's convergence is not useful for inference because no one would be willing to use this as an estimator (far more complicated than the lasso without offering any additional benefit). The distributional approximation in Theorem 3.2 in the present form is not attractive, but it would be if p is allowed to grow and a sparse normal approximation is established. Theorem 3.4 is the only result of interest apart from a possibly upgraded Theorem 3.2, but a thorough comparison with the bootstrap literature is needed (both theoretically and numerically). Section 5 gives the impression that the results are valid for a lot more general scheme of weights. If that is fully true, I hardly see any point in doing the special case of exponential first, and then repeat the results for the general case (with appropriate conditions on the weights). The results should be unified, but if this is not possible, the results may be just restricted to the exponential case. The same remark applies to the weights on the penalty. A general form allowing flexibity in weights in both loss and penalty is preferable, from which all individual cases may be concluded. The initial part of Appendix A is too familiar, and may be dropped. 

In summary, the paper at its present form is not attractive, but there are potentially interesting results. It appears that the paper may be substantially condensed by focusing on the setup of interest only and results using general weights. Numerical performance should be reported and a thorough comparison with comparable results from the bootstrap and the Bayesian literature should be presented. The referee's comments should be thoroughly addressed. 

 

